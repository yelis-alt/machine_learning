---
title: "Bicycles"
---

# Настройка вывода данных:

```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(width = 100) # ширина текстового вывода
options(digits = 6) # число знаков после запятой в выводе
```

# Подключение необходимых библиотек:

```{r}
library(lubridate)
library(ggrepel)
library(readr)
library(tidyverse)
library(ggplot2)
library(ggfortify)
library(modelr)
library(broom)
library(GGally)
library(forcats)
library(tidyr)
library(car)
library(dplyr)
library(memisc)
library(gridExtra)
```



# Описание переменных:

- `datetime`: дата и время аренды велосипеда;	
- `season`: время года (1 - весна, 2 - лето, 3 - осень, 4- зима); 
- `holiday`: выходной (1 - да, 0 - нет); 
- `workingday`: рабочий день (1 - да, 0 -нет);	  
- `weather`: качественная характеристика погодных условий:  
1: Ясно, малооблачно, немного облачно;
2: Туманно и облачно, малооблачно, переменно облачно;
3: Лёгкий снегопад, лёгкий дождь с громом и перистыми облаками, лёгкий дождь с перистыми облаками;
4: Ливень, град, гром, туман, снег;
- `temp`: температура в цельсиях;	
- `atemp`: температура в цельсиях (по ощущениям);	
- `humidity`: относительная влажность;
- `windspeed`: скорость ветра; 
- `casual`:  число актов аренды велосипедов незарегестрированными пользователями; 
- `registered`:  число актов аренды велосипедов зарегестрированными пользователями; 
- `count` - целевая переменная: общее число актов аренды;

# 1) Подготовка исходных данных:

## Загрузка исходных данных

```{r}
bike <- read_csv ("./bike.csv")
```

**Вывод:** была загружена база данных по арендам велосипедов. Она содержит в себе 10886 наблюдений, которые представляют собой акты аренды велосипедов с предшествующими ими внешними условиями, такими как погодные условия, сезон, календарный день и т.д. - над ней будет проводиться анализ и поиск подходящей модели прогнозирования. Нам необходимо подготовить данные к анализу и разбить базу данных на обучающую и тестовую выборки случайным образом, и именно к тестовой выборке будет применяться выявленная на обучающей выборке лучшая модель для прогнозирования значений актов аренды велосипедов.

## Подготовка данных к анализу

Удалим переменные "registered" и "casual" в нашей выборке, потому что они являются лишь слагаемыми нашей целей переменной "count", поэтому не несут в себе большой значимости и могут изменить модели корреляции по причине их сильной зависимости от целевой переменной:

```{r}
bike <- bike[,-(10:11)] 

```

Удалим времена года и выделим из дат месяца в обучающей и тестовой выборках, а также время, чтобы повысить точность нашего анализа, который может быть основан на месяцах, а не просто временах года:

```{r}
## Удаление времён года
bike <- bike[,-2]

## Создание отдельных столбцов с временем и датой в выборках
bike$month <- as.Date(bike$datetime) 
bike$time <- format(as.POSIXct(bike$datetime) ,format = "%H:%M:%S")

## Удаление объединённого столбца в выборках
bike <- bike[,-1]

## Выделение месяцев из дат
bike$month <- format(bike$month, "%m")

## Выделение часов из времени
bike$time <- substr(bike$time, start = 1, stop = 2)
```

## Изменение типа данных даты и времени

```{r}
bike$month <- as.numeric(as.character(bike$month))
bike$time <- as.numeric(as.character(bike$time))
```

## Разграничение времён суток

```{r}
bike <- mutate (bike,
                daytime = ifelse(time >= 0, ifelse(time<=6, 1,ifelse(time<=12, 2,ifelse (time <=17,3, 4))), 0))

## Удаление ненужного столбца с часами
bike <- bike[,-10]
```

## Описание новых переменных

- `holiday`: выходной (1 - да, 0 - нет); 
- `workingday`: рабочий день (1 - да, 0 -нет);	  
- `weather`: качественная характеристика погодных условий:  
1: Ясно, малооблачно, немного облачно;
2: Туманно и облачно, малооблачно, переменно облачно;
3: Лёгкий снегопад, лёгкий дождь с громом и перистыми облаками, лёгкий дождь с перистыми облаками;
4: Ливень, град, гром, туман, снег;
- `temp`: температура в цельсиях;	
- `atemp`: температура в цельсиях (по ощущениям);	
- `humidity`: относительная влажность;
- `windspeed`: скорость ветра; 
- `month`: месяц года (от 1 до 12);
- `daytime`: время суток:
1: ночь;
2: утро;
3: день;
4: вечер;
- `count` - целевая переменная: общее число актов аренды;

## Получение обучающей и тестовой выборки

```{r}
sample <- floor(0.8*nrow(bike))

set.seed(10886)

sample_ind <- sample(seq_len(nrow(bike)),size = sample)

bike_train <- bike[sample_ind,]
bike_test <- bike[-sample_ind,]
```


Прежде чем начать моделирование, необходимо выяснить: как сильно на корреляцию влияют удаленные столбцы registered и casual.Так как целевая переменная count = registered+casual, очевидно, что значение двух нецелевых переменных влияют напрямую на целевую. Задание по прогнозированию: прогноз переменной count. Поэтому, при анализе и моделировании необходимо исключить registered и casual. Однако, чтобы не потерять скрытые зависимости, которые несут в себе удаленные столбцы, проведем анализ этих столбцов на зависимости. В лучшем исходе registered и casual должны показывать одинаковые зависимости и тренды, что позволило построить модель без них и без ухудшения самой модели.

# 2) Разведочный анализ:

## Изучение взаимосвязей факторов с числом зарегистрированных/незарегистрированных клиентов для выявления новых закономерностей для подбора переменных в моделях

Загрузим изначальную выборку с переменными "registered" и "casual". Сделаем отношение в 0.75, которое означает, что если в одном наблюдении более 75% арендаторов велосипедов были зарегистрированными, то считается, что во время этого наблюдения были только зарегистрированные клиенты, если менее - то только незарегистрированные. Такая большая доля выбрана потому, что число незарегистрированных пользователей почти всегда незначительна.

```{r}
bike_orig <- read_csv ("./bike.csv")
bike_orig <- mutate(bike_orig, relation = ifelse(registered/count >= 0.75, "registered", "casual"))
```

```{r}
graph1 <- bike_orig %>%

  ggplot(aes(count, temp, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "1", colour = "Тип клиента", x = "Число актов аренды", y = "t воздуха")

graph2 <- bike_orig %>%

  ggplot(aes(count, atemp, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "2", colour = "Тип клиента", x = "Число актов аренды", y = "t воздуха по ощущениям")

graph3 <- bike_orig %>%

  ggplot(aes(count, weather, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "3", colour = "Тип клиента", x = "Число актов аренды", y = "Cостояние погоды")

graph4 <- bike_orig %>%

  ggplot(aes(count, season, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "4", colour = "Тип клиента", x = "Число актов аренды", y = "Сезон")

grid.arrange(graph1, graph2, graph3, graph4, ncol=2)
```

**Вывод:**

1 график: можно заметить, что при высокой температуре воздуха существует тенденция для незарегистрированных пользователей для обращения к аренде велосипедов. Для зарегистрированных пользователей температура не так важна - их число актов аренды распределено равномерно;

2 график: закономерности практически идентичные графику №1;

3 график: можно заявить, что во время самой плохой степени погоды берётся крайне мало велосипедов, но вся их аренда производится только зарегистрированными пользователями. В остальных случаях, есть как зарегистрированные, так незарегистрированные пользователи (зарегистрированных по-прежнему больше);

4 график: можно заметить, что во время зимнего сезона арендуют велосипеды практически только зарегистрированные пользователи. Больше всего незарегистрированных пользователей арендуют велосипеды весной и летом;

```{r}
graph5 <- bike_orig %>%

  ggplot(aes(count, workingday, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs (title = "5", colour = "Тип клиента", x = "Число актов аренды", y = "Будние дни")

graph6 <- bike_orig %>%

  ggplot(aes(count, holiday, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "6", colour = "Тип клиента", x = "Число актов аренды", y = "Праздничные дни")

graph7 <- bike_orig %>%

  ggplot(aes(count, windspeed, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "7", colour = "Тип клиента", x = "Число актов аренды", y = "Скорость ветра")

graph8 <- bike_orig %>%

  ggplot(aes(count, humidity, color = relation)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title = "8", colour = "Тип клиента", x = "Число актов аренды", y = "Влажность")

grid.arrange(graph5, graph6, graph7, graph8, ncol=2)
```

**Вывод:**

5 график: можно заметить, что в выходные дни есть тенденция для незарегистрированных пользователей прибегать к аренде велосипедов, в то время как в будние дни берут велосипеды практически только зарегистрированные пользователи;

6 график: можно заметить, что в праздничные есть тенденция для незарегистрированных пользователей прибегать к аренде велосипедов, в то время как в обычные дни берут велосипеды практически только зарегистрированные пользователи;

7 график: нет практически никакой зависимости между регистрацией пользователя и скоростью ветра. Все типы клиентов распределены случайным образом;

8 график: можно заметить, что при низкой влажности больше незарегистрированных пользователей берёт велосипеды в аренду. Тем не менее, эта зависимость выражена слабо - можно сказать, что влажность тоже не влияет на тенденцию типов клиентов к аренде велосипедов;

**Вывод:** анализ зависимостей показал значительные несовпадения зависимостей переменных с рабочими днями, сезоном (месяцы) и влажность. Используя эти переменные при моделировании стоит быть аккуратными, т.к. их применение может исказить реальную ситуацию, что даст большую ошибку при прогнозировании.

## Статистический анализ выборок

```{r}
summary (bike_train)
summary (bike_test)
```

**Вывод:** статистический анализ переменных показал, что пустые ячейки отсутствуют, а также существуют возможные выбросы для переменных "windspeed" и "count" в связи большими отклонениями максимальных значений от 3 квартилей. Тем не менее, эти выбросы могут быть объяснены моделью и не являться для неё преградой, поэтому будет проведена отдельная работа с выбросами, которая выявит их значимость для работы моделей.

Также можно заметить, что в датасетах присутствуют 5 качественных переменных (holiday, workingday, weather, month и daytime) и 5 количественных переменных (temp, atemp, humidity, windspeed, count). Качественные переменные выражены количественными категориями, поэтому проведения работ по преобразованию их в "долгий" текстовый тип не нужно - они готовы к работе без дополнительных преобразований. Среди качественных переменных выбросов не было обнаружены, все их количественные предикторы лежат в определённых диапазонах, что исключает возможность опечатки при их заполнении.

## Диаграммы рессеяния и коэфициенты корреляции

```{r echo=FALSE, message=FALSE}
ggpairs(bike_train, 
        lower = list(continuous = wrap("smooth_lm", color = 'blue')))
```

**Вывод:** На диаграммах рассеяния видна зависимость между всеми параметрами. Коэффициенты корреляции ненулевые и статистически значимы.
Наибольшее влияние на целевую переменную оказывают время суток, температура воздуха (по ощущениям тоже) и влажность. Наибольшая корреляция между переменными - temp и atemp, но это очевидно, ведь температура воздуха по ощущениям в наибольшей степени зависит от фактической. Влажность воздуха имеет достаточно большой коэффициент корреляции с типом погоды, что также может быть легко объяснено, в то время как скорость ветра в некоторой степени зависит от влажности, а значит и от погоды. Месяц года имеет хороший коэффициент корреляции с температурой воздуха и его влажностью, что также очевидно, ведь в разные времена года разные температурные режимы и состояние воздуха в связи с их цикличностью. В остальных случаях, поверхностного анализа недостаточного - необходим более детальный анализ, либо проверка работы моделей с взаимосвязями переменных, что и будет проделано в рамках этого проекта.

# 3) Ручные регрессионные модели:

## Модель №1: 'count' ~ 'daytime'

```{r}
model_1 <- lm(count ~ daytime, data = bike_train)
summary(model_1)
```

**Вывод:** время суток и число актов аренды показывали наибольшую корреляцию, поэтому было решено построить модель с такими зависимостями первой. Данная модель регрессии статистически значимая, так как p-value = 2e-16 (<0.05). 

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance(model_1) 
```

**Вывод:** модель смогла объяснить только 18.3% наблюдений, и её стандартная ошибка равна 164, что говорит о том, модель очень плохо справляется своими задачами и нуждается в замене альтернативами. 

## Модель №2: 'count' ~ 'daytime' + 'temp' + 'atemp'+ 'humidity'

```{r}
t1<- car::powerTransform(count ~ temp + atemp + daytime + humidity, data = bike_train)
coef(t1)
```



```{r}
model_2 <- lm(count^0.274 ~ temp + atemp +I(atemp^2) + daytime +I(daytime^2) + humidity, data = bike_train)
summary(model_2)
```

**Вывод:** Следующая модель - это модель с несколькими переменными, которые имеют наибольшие коэффициенты корреляции с целевой. Все, кроме одного коэффициента в модели, значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).


**Построение графиков остаточной диагностики:**

```{r}
autoplot (model_2)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки относительно близко прилегают к прямой (особенно в центре), а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Модель 3: "Полная"

Перебирать отдельно набор переменных - долго. Воспользуемся построением полной модели.

В этой модели будет изучено влияние одновременно всех переменных выборки на целевую.

```{r}
model_3 <- lm(count ~ ., data = dplyr::select(bike_train, `holiday`:`daytime`))
summary (model_3)
```

**Вывод:** было решено сделать общую модель со всеми влиятельными переменными. Полная модель оказалась значима (p-value: <2e-16), несмотря на то что некоторые её коэффициенты не значимы, что говорит о целесообразности её дальнейшего тестирования.

```{r paged.print=FALSE}
glance (model_3)
```

**Вывод:** модель опять чуть лучше справилась со своей задачей - она объяснила 35.3% всех наблюдений, и её стандартная ошибка = 146. 

**Построение графиков остаточной диагностики:**

```{r}
autoplot (model_3)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки относительно близко прилегают к прямой (особенно в центре), а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Перебор с помощью "пустой" модели

Ручной перебор всех 9 переменных с целевой занял бы крайне много времени, поэтому можно оставить эту задачу компьютеру, а потом посмотреть, какие же сочетания давали наилучшие результаты. Воспользуемся информационным критерием AIc, который покажет нам, какие лучшие модели ему удалось выявить.

```{r}
model_empty <- lm(count ~ 1, data = dplyr::select(bike_train, `holiday`:`daytime`))

m_forward <- stepAIC(model_empty, 
                     scope = list(lower = model_empty, upper = model_3),
                     direction = 'forward')
```

**Вывод:** наименьшим AIC = 86821 (Информационный критерий Акаике для статистики качества приближения) обладает подобранная модель С переменными: время суток, температура воздуха, влажность, месяц, температура по ощущениям (+скорость ветра). Стоит проанализировать эту модель для проверки качества её работы.

## Модель №4: count ~ daytime + temp + humidity + month + atemp + windspeed

```{r}
model_4 <- lm(count ~ daytime + temp + humidity + month + atemp + windspeed, data = bike_train)
summary(model_4)
```

**Вывод:** все, кроме двух коэффициентов в модели, значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance (model_4)
```

**Вывод:** модель уже лучше справилась со своей задачей - она объяснила по-прежнему объяснила 35,3% всех наблюдений, но её стандартная ошибка = 146.  

**Построение графиков остаточной диагностики:**

```{r}
autoplot (model_4)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки относительно близко прилегают к прямой (особенно в центре), а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Модель №5: count ~ daytime + humidity + month + atemp

В этой модели му удалили незначимую переменную из прошлой модели и проверяем изменение работы модели после этого действия.

```{r}
model_5 <- lm(count ~ daytime + humidity + month + atemp, data = bike_train)
summary(model_5)
```

**Вывод:** все коэффициенты в модели значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance (model_5)
```

**Вывод:** модель также справилась со своей задачей - она объяснила по-прежнему объяснила 35,3% всех наблюдений, но её стандартная ошибка = 146.  

**Построение графиков остаточной диагностики:**

```{r}
autoplot (model_5)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки относительно близко прилегают к прямой (особенно в центре), а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, и они хуже объясняются, чем в предыдущий модели.

## Изучение взаимосвязей между переменными для построения моделей с учётом взаимосвязей факторов

**Теперь отойдём от применения простых регрессионных моделей и рассмотрим более сложные. Для визуализации нескольких регрессионных прямых, преобразуем рассматриваемые переменные в отдельных данных в качественные:**

```{r}
bike_train1 <- bike_train 
  bike_train1$daytime <- as.character(bike_train1$daytime) 

bike_train1 <- bike_train1
  bike_train1$weather <- as.character(bike_train1$weather) 

bike_train1 <- bike_train1
      bike_train1$month <- as.character(bike_train1$month) 
        
bike_train1 <- bike_train1
      bike_train1$workingday <- as.character(bike_train1$workingday) 
```

**Теперь построим визуализации регрессионных прямых:**

```{r}
dots1 <- bike_train1 %>%
  ggplot(aes(count, temp, color = workingday)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title="1", colour = "Рабочие дни", x = "Число актов аренды", y = "Температура воздуха")

dots2 <-bike_train1 %>%

  ggplot(aes(count, temp, color = daytime)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title="2",colour = "Время суток", x = "Число актов аренды", y = "Температура воздуха")

dots3 <-bike_train1 %>%

  ggplot(aes(count, temp, color = month)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title="3", colour = "Месяц", x = "Число актов аренды", y = "Температура воздуха")

dots4 <-bike_train1 %>%

  ggplot(aes(count, temp, color = weather)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'lm', se = F)+
  labs(title="4",colour = "Состояние погоды", x = "Число актов аренды", y = "Температура воздуха")

grid.arrange(dots1, dots2, dots3, dots4, ncol=2)
```

**Вывод:** 

1 график: Какой-либо зависимости между переменными не замечено. Можно сказать, что происходит много актов аренды при высокой температуре воздуха в выходные данные, но данная закономерность выражена слаба. Всё же никаких взаимосвязей между этими переменными обнаружено не было;

2 график: можно заявить, что независимо от температуры воздуха, в ночное время суток берётся в аренду крайне низкое число велосипедов. В остальные времена суток - распределение актов аренды равномерно и не зависит от температуры воздуха;

3 график: можно заметить, что в зимние времена года, когда присутствует низкая температура воздуха, число актов аренды минимально. В остальных месяцах число актов аренды распределено равномерно без подчинения к температуре воздуха;

4 график: сразу бросается в глаза тот факт, что большинство актов аренды происходят во время погоды, при которой ясно, малооблачно или немного облачно. Крайне мало велосипедов арендовалось во время ливня, града, грома, тумана и снега. Другими словами, состояние погоды влияет на число актов аренды по ухудшению ей условий (1 тип -наибольшее число, 4 тип - наименьшее число);

## Модель №6: count ~ temp +  daytime + humidity + daytime*workingday + month + weather*daytime

```{r}
model_6<- lm(count ~ temp +  daytime + humidity + daytime*workingday + month + weather*daytime, data = bike_train)
summary(model_6)
```

**Вывод:** все коэффициенты в модели значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

**Проверка параметров работы моделей:**

```{r paged.print=FALSE}
glance(model_6)
```

**Вывод:** модель объяснила 35.4% наблюдений, а стандартное отклонение = 146. Пока что эта модель с взаимосвязями между переменными показала наилучшие результаты. 

**Диагностические графики:**

```{r}
autoplot (model_6)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики).

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки относительно близко прилегают к прямой (особенно в центре), а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Левередж = 3*10/8708 = 0.0035
Выбросы есть, но в целом модель несильно подстраивается под них.
Достаточно много наблюдений выходят за допустимые границы, т.е. являются весомыми при построении модели. Возможно, стоит произвести анализ выбросов.

# Исследование работ моделей без выбросов и без гетеродоксичности

```{r}
model_6a <- model_6 %>% 
  fortify() %>% # сохранили остатки, предсказания и показатели влиятельности в набор
  merge(., bike_train) # добавили исходные данные (merge удаляет дублирующийся при слиянии столбцы)


ggplot(model_6a, aes(.fitted, count)) +
  geom_point(aes(size = .cooksd, colour = .hat)) +
  geom_line(aes(.fitted, .fitted), 
            colour = "red", linetype = "dashed") +
  scale_colour_gradient(low = "black", high = "red") +
  ggrepel::geom_label_repel(
    data = filter(model_6a, .cooksd > 4/nrow(bike_train)),
    mapping = aes(label = "danger"), alpha = 0.25) +
  labs(title = "Влиятельные наблюдения",
       x = "Прогноз count", y = "Факт count", 
       colour = "Левередж", size = "Расстояние Кука")
```

## Модель №7: count ~ temp +  daytime + humidity + daytime*workingday + month + weather*daytime (без выбросов и гетеродоксичности)

**Влиятельные наблюдения помечены словом "danger", что говорит об опасности использования данных наблюдений в модели, которые негативно на нее влияют. Уберем выбросы и пересчитаем лучшие прогнозы и ошибки моделей:**


```{r}
model_6a$.cooksd <- as.numeric(model_6a$.cooksd)
model_6a$.cooksd[is.na(model_6a$.cooksd)] <- mean(model_6a$.cooksd, na.rm = T)

bike_train_clean <- model_6a %>%
  filter(.cooksd < 4/nrow(model_6a)) 

```

**Определение степени целевой переменной для устранения гетеродоксичности:**

```{r}
t3<- car::powerTransform(count ~ temp +  daytime + humidity + daytime*workingday + month + weather*daytime, data = bike_train_clean)
coef(t3)
```

**Построение модели:**

```{r}
model_6b<- lm(count^0.308 ~ temp +  daytime + I(daytime^2)+ workingday + I(month^2)+ humidity + daytime*workingday + month + weather*daytime, data = bike_train_clean)
summary(model_6b)
```

**Вывод:** все коэффициенты в модели, кроме одного, значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

**Диагностические графики:**

```{r}
autoplot(model_6b)
```


**Вывод:** практически все диагностические графики демонстрируют превосходную работу модели. Самое главное, что нам удалось добиться практически полной горизонтальной прямой на 3-ем графике.

## Модель №8: count ~  atemp + daytime + humidity + daytime*workingday + month + weather*daytime (без выбросов и без гетеродокчиности)

**Поменяем в модели без выбросов переменную temp на переменную atemp, которая обладала большим коэффициентом корреляции при разведочном анализе:** 

```{r}
t4<- car::powerTransform(count ~  atemp + daytime + humidity + daytime*workingday + month + weather*daytime, data = bike_train_clean)
coef(t4)
```

**Построение модели:**

```{r}
model_6b1<- lm(count^0.308 ~  atemp + daytime+I(daytime^2) + humidity + daytime*workingday + month + weather*daytime, data = bike_train_clean)
summary(model_6b1)
```

**Вывод:** все коэффициенты в модели, кроме одного, значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

## Модель №9: count ~  atemp + daytime + humidity + daytime*workingday + month*daytime + weather*daytime + windspeed + humidity*month (без выбросов и без гетеродоксичности)

**Определеим степень, в которую необходимо возвести целевую переменную, чтобы сделать нашу лучшую модель гомодоксичной:**

```{r}
t2<- car::powerTransform(count ~  atemp + daytime + humidity + daytime*workingday + month*daytime + weather*daytime + windspeed + humidity*month, data = bike_train_clean)
coef(t2)
```

**Построение модели:**

```{r}
model_6b2m<- lm(count^0.314 ~  atemp + daytime + I(daytime^2) + humidity + daytime*workingday + month*daytime + weather*daytime +  humidity*month + humidity*daytime, data = bike_train_clean)
summary(model_6b2m)
```

**Вывод:** не все коэффициенты в модели значимые, но сама она статистически значимая p-value < 2e-16 (<0.05).

```{r}
autoplot(model_6b2m)
```

**Вывод:** практически все диагностические графики демонстрируют превосходную работу модели. Самое главное, что нам удалось добиться практически полной горизонтальной прямой на 3-ем графике.

# 4) Регрессионные модели, основанные на деревьях решений

## Модель №10: обычное дерево решений

**Подключение необходимых библиотек для работы с деревьями решений:**

```{r}
library(scales) # Процентный формат для осей ggplot
library(rpart) # Деревья в R: recursive partitioning
library(party) # Деревья в R: conditional inference
library(rpart.plot) # Визуализация деревьев
library(partykit) # Визуализация деревьев
library(C50) # Деревья в R: C5.0
library(mlr)
 
```

**Построение автоматически подобранного дерева решений на обучающей выборке:**

```{r}
rtree <- rpart(formula = count~., data = bike_train)
summary(rtree)
rpart.plot(rtree)
```

**Вывод:** верхнее число над процентом (191, 256 и т.д.) - это среднее число арендованных велосипедов, исходя из условий отбора. Данная модель, по сути, способна прогнозировать только 6 значений count для каждого дня.
Модель самостоятельно отобрала, по её мнению, самые важные/значимые переменные - daytime, temp, humidity, month. Примерно такие же переменные были отобраны при ручном моделировании. Значит, данной модели можно доверять. Попробуем увеличить число ветвей - это позволит повысить число прогнозируемых значений, что в теории должно повысить точность. Тем не менее, позже построим работу этой модели на обучающей выборке.

## Модель №11: дерево решений с модифицированной cp

**Вычисление среднего значения арендованных велосипедов за весь обучающий период:**

```{r}
mean(bike_train$count)
```

**Создание дополнительного столбца с разделение в числах актов аренды велосипедов по признаку "больше или меньшее, чем среднее":**

```{r}
bike_train_a <- bike_train %>%
  mutate( count1 = ifelse(count>=191, "much", "less"))
```

**График рассеяния актов аренды велосипедов в разрезе времени суток, температуры и с разделением по признаку "больше или меньшее, чем среднее":**

```{r}
cmap <- c("much" =  "green", "less" =  "red")

ggplot(bike_train_a, aes(x = daytime, y = temp)) +
  geom_jitter(aes(colour = count1), alpha = 0.5) +
  labs(title = "Сравнение числа актов аренды велосипедов и его среднего значения", colour = "Число аренды в день", x = "Время суток", y = "t воздуха") +
  scale_x_continuous(breaks = 1:10) +
  scale_colour_manual(values = cmap)
```

**Вывод:** можно заметить, что ночью практически каждое наблюдение содержит число актов аренды меньшее, чем среднее значение за весь обучающий период, а также низкая температура воздуха, независимо от времени суток негативно влияет на желание людей брать велосипеды и они берут их реже обычного.

**Построение модифицированного дерева решений:**

```{r}
rtree_overfit <- rpart(count ~ ., 
                          data = bike_train,
                          control = 
                            rpart.control(
                              minsplit = 2, # минимальное число примеров для разбиения
                              cp = 0.00001, # минимальное относительное улучшение для разбиения
                              maxdepth = 20 # максимальная глубина для листа
                            ))

rpart.plot(rtree_overfit)
```

**Вывод:** модель получилась чересчур сложной, она нуждается в упрощении.

**Посмотрим на зависимость относительной ошибки от cp:**

```{r}
plotcp(rtree_overfit)
```

**Вывод:** можно увидеть, как сложность модели влияет на ее точность. Попробуем установить параметр сложности (ср) равный 0.0003.

**Древо решений с оптимальной cp:**

```{r}
rtree_overfit1 <- prune(rtree_overfit, cp = 0.0003)
rpart.plot(rtree_overfit1)
```

**Вывод:** модель стала проще, но тем не менее, по-прежнему сложна. Также её прогноза на обучающей выборке

## Модель №12: полное дерево решений

**Посмотрим на полную дерево решений по обучающей выборке:**

```{r}
rctree <- ctree(count ~ ., data = bike_train)
plot(rctree)
```

**Вывод:** она оказалась так же сложна. На всякий случай проверим точность её прогноза на обучающей выборке.

# 5) Автоматические регрессионные модели:

## Модель № 13: линейная регрессия

**Подключение необходимых библиотек для работы с автоматическими моделями:**

```{r}
library(tidyverse) # трансформация и визуализация данных
library(mlr) # фреймворк для машинного обучения
library(stringr) # работа со строками
library(forcats) # работа с факторами
library(parallelMap) # распараллеливание задач
library(rpart.plot) # визуализация деревьев rpart
```

**Создадим задачу для автоматической модели: целевая переменная count, данные bike:**

```{r}
bike_task <- makeRegrTask(id = "Аренда велосипедов", 
                         data = bike, target = "count",
                         fixup.data = "warn")
print(bike_task)
```

**Посмотрим, какие модели существуют для автоматического прогнозирования на основе регрессии:**

```{r paged.print=FALSE}
listLearners(obj = "regr") %>%
  dplyr::select(name, class) %>% 
  mutate(name = substr(name, 1, 60)) %>%
  head(10) %>%
  arrange(name)
```

**Поиск точного количества таких моделей**

```{r paged.print=FALSE}
listLearners(obj = "regr") %>% count()
```

**Вывод:** их количество - 59.

**Прогноз по самым популярным и точным моделям: линейная регрессия:**

```{r}
lrn_lm <- makeLearner("regr.lm", id = "Линейная регрессия")
lrn_lm
```

**Взаимосвязь коэффициентов модели и её проверка:**

```{r paged.print=FALSE}
m_lm <- train(lrn_lm, bike_task)

m_lm %>% 
  getLearnerModel() %>%
  summary()
```

**Вывод:** некоторые переменные не значимы, но в целом, модель можно использовать, так как сама она статистически значима?: p-value<0.05.

**Разделение данных на обучающий и тестовый период для работ с автоматическими моделями:**

```{r}
# Получаем номера строк для обучающей и тестовой выборки
set.seed(123) # для воспроизводимости
bike_n <- getTaskSize(bike_task)
bike_train_task <- sample(bike_n, size = bike_n * 0.7)
bike_test_task <- base::setdiff(1:bike_n, bike_train_task)

# Строим модель только на обучающей выборке
bike_mod_lm <- train(lrn_lm, task = bike_task, 
                    subset = bike_train_task)
```

**Прогноз с помощью неё на обучающем периоде:**

```{r}
bike_pred_lm <- predict(bike_mod_lm, 
                       task = bike_task, 
                       subset = bike_train_task)

bike_pred_lm
```

**Расчет ошибок модели:**

```{r}
reg_ms <- list(rmse, mape, mae)

performance(bike_pred_lm,
            measures = reg_ms) %>%
  round(2)
```

**Вывод:**точность модели плохая, поэтому будут использованы альтернативные автоматические модели для их последующего включение в отбор.

## Модель: randomforest - также одна из самых популярных

```{r}
lrn_lm1 <- makeLearner("regr.randomForest")
lrn_lm1
```

**Присвоение модели выборки:**

```{r}
m_lm1 <- train(lrn_lm1, bike_task)
```

**Просмотр показателей модели (переменные), которые сложно интерпретировать:**

```{r}
m_lm1 %>% 
  getLearnerModel() %>%
  summary()
```

**Разделение данных на обучающую и тестовую выборки и прогноз:**

```{r}
# Получаем номера строк для обучающей и тестовой выборки
set.seed(123) # для воспроизводимости
bike_n1 <- getTaskSize(bike_task)
bike_train_task1 <- sample(bike_n1, size = bike_n1 * 0.7)
bike_test_task1 <- base::setdiff(1:bike_n1, bike_train_task1)

# Строим модель только на обучающей выборке
bike_mod_lm1 <- train(lrn_lm1, task = bike_task, 
                    subset = bike_train_task1)

bike_pred_lm1 <- predict(bike_mod_lm1, 
                       task = bike_task, 
                       subset = bike_train_task1)

bike_pred_lm1
```

**Расчет ошибок модели на обучающем периоде:**

```{r}
reg_ms1 <- list(rmse, mape, mae)

performance(bike_pred_lm1,
            measures = reg_ms) %>%
  round(2)
```
**Вывод:**
Малые ошибки модели связаны с тем, что randomForest в результате обучения использует не одно, а несколько деревьев решений, которые по отдельности показывают не лучшие результаты. Точность получилась неплохой не из-за того, что данный метод для оценки хороший, а за счет чересчур множественных ответвлений и условий при построении дерева. Возможно, что тестовый период окажется не таким точным.

Модель уже лучше, по сравнению с lm, но скорее всего, уступает ручным моделям. Тем не менее, она поучаствует в конкурсе.

*Далее, мы решили посчитать прогноз по модели "нечетких множеств". В течение нашего обучения мы часто сталкивались с данным подходом, который помогал решать множество логистических задач, связанных с неопределенностью. Здесь не будут представлены chunks с этой моделью, т.к. ее выполнение требует очень долгого времени и в целом нагружает компьютер. Однако, ошибки модели будут представлены:
rmse: 132.58
mape: 1.87
mae: 94.95
Результаты ошибок не самые лучшие, значит, модель не будет участвовать в борьбе за лучшую

## Модели №14: "bcart"

MLR содержит 59 моделей регрессии, считать каждую вручную - нецелесообразно. Попробуем отобрать модели, наиболее подходящие к исследуемым данным.
Исходя из характеристик, которыми могут быть описаны модели, выделим 2 значимые:
1) SE - позволяет рассчитывать и прогнозировать стандартные ошибки модели. это позволит выбирать лучшую модель.
2) Numeric - позволяет прогнозировать числовые переменные (count - целевая числовая переменная)
В остальном данные не имеют каких-либо особых характеристик, которые позволили бы отобрать подходящие модели.

```{r paged.print=FALSE}
listLearners(obj = "regr", properties = c("se", "numerics")) %>%
  dplyr::select(name, class) %>% 
  mutate(name = substr(name, 1, 60)) %>%
  head(50) %>%
  arrange(name)
```

**Вывод:** итого было отобрано 16 моделей, соответствующие заданным параметрам.

**Подключение необходимых библиотек для работы с отобранными моделями:**

```{r}
library(tgp)
library(GPfit)
library(DiceKriging)
library(laGP)
library(ranger)
library(crs)
```

**Вывод:** lm и randomforest уже расчитаны. Уберем их.

**Создание нескольких моделей:**

```{r}
turnover_learners <- 
  makeLearners(cls = c("bcart", "bgp", "bgpllm", "blm", "btgp", "btgpllm", "btlm", "GPfit","gausspr", "glm", "km", "laGP",  "ranger", "crs" ),
               ids = c("bcart", "bgp", "bgpllm", "blm", "btgp", "btgpllm", "btlm", "GPfit","gausspr", "glm", "km", "laGP",  "ranger", "crs"),
               type = "regr", predict.type = "se")


```

**Создаем задачу - обозначаем целевую переменную:**

```{r}
turnover_task <- makeRegrTask(id = "Аренда велосипедов", 
                         data = bike, target = "count",
                         fixup.data = "warn")
```

**Облегчение процесса расчета прогнозов:**

```{r}
set.seed(123, "L'Ecuyer") # При использовании параллельных вычислений необходимо выбирать алгоритм генерации СЧ "L'Ecuyer"

# Определение количества доступных ядер процессора
num_cores <- parallel::detectCores()

# Запуск параллельных вычислений
parallelStartSocket(num_cores) # для Windows


```

**Вывод** прогнозирование (Данный chunk не выполняется до конца - видимо требует слишком много оперативной памяти, компьютеры не справляются. При уменьшении числа моделей в makelearners ситуация не меняется. Было принято решение - рассчитать модели вручную по отдельности. Ошибки моделей будут представлены ниже.)

**turnover_bench <- turnover_learners %>% benchmark(tasks = turnover_task, show.info = FALSE)**

"bcart", "bgp", "bgpllm", "blm", "btgp", "btgpllm", "btlm", "GPfit","gausspr", "glm", "km", "laGP",  "ranger", "crs" 

**Постановка задачи моделям:**

```{r}
lrn_bcart <- makeLearner("regr.bcart")
lrn_bcart
```

**Присвоение моделям выборки:**

```{r}
m_bcart1 <- train(lrn_lm1, bike_task)
```

**Показатели модели (переменные), которые сложно интерпретировать:**

```{r}
m_bcart1 %>% 
  getLearnerModel() %>%
  summary()
```

**Разделение данных на обучающую и тестовую выборки и прогноз:**

```{r message=FALSE}
# Получаем номера строк для обучающей и тестовой выборки
set.seed(123) # для воспроизводимости
bike_n1 <- getTaskSize(bike_task)
bike_train_task1 <- sample(bike_n1, size = bike_n1 * 0.7)
bike_test_task1 <- base::setdiff(1:bike_n1, bike_train_task1)

# Строим модель только на обучающей
bike_mod_bcart1 <- train(lrn_bcart, task = bike_task, 
                    subset = bike_train_task1)

bike_pred_bcart1 <- predict(bike_mod_bcart1, 
                       task = bike_task, 
                       subset = bike_train_task1)

bike_pred_bcart1
```

**Расчет ошибок моделей:** 

```{r}
reg_ms1 <- list(rmse, mape, mae)

performance(bike_pred_bcart1,
            measures = reg_ms) %>%
  round(2)
```

**Вывод:** как оказалось, из-за технических особенностей наших компьютеров, наша команда не может рассчитать модели и их ошибки из-за очень длительного процесса вычисления. Спрогнозировав 3 модели видно, что в целом целевая ошибка «MAPE» гораздо выше, чем у моделей, рассчитанных вручную.
К сожалению, пришлось ограничится только этими моделями.

## 6) Выбор лучшей модели

**Прогноз на обучающем периоде:**

```{r}
model_2_pred <- bike_train %>%
  add_predictions(model_2, var = "Predicted") %>%
  dplyr::select(count, Predicted)%>%
mutate(Predicted = Predicted^(1/0.274))
 
model_3_pred <- bike_train %>%
  add_predictions(model_3, var = "Predicted") %>%
  dplyr::select(count, Predicted)
  
model_4_pred <- bike_train %>%
  add_predictions(model_4, var = "Predicted") %>%
  dplyr::select(count, Predicted)

model_5_pred <- bike_train %>%
  add_predictions(model_5, var = "Predicted") %>%
  dplyr::select(count, Predicted)

model_6_pred <- bike_train %>%
  add_predictions(model_6, var = "Predicted") %>%
  dplyr::select(count, Predicted) 

model_7_pred <- bike_train %>%
  add_predictions(model_6b, var = "Predicted") %>%
  dplyr::select(count, Predicted) %>%
mutate(Predicted = Predicted^(1/0.308))

model_8_pred <- bike_train %>%
  add_predictions(model_6b1, var = "Predicted") %>%
  dplyr::select(count, Predicted) %>%
mutate(Predicted = Predicted^(1/0.308))

model_9_pred <- bike_train %>%
  add_predictions(model_6b2m, var = "Predicted") %>%
  dplyr::select(count, Predicted) %>%
mutate(Predicted = Predicted^(1/0.314))

model_rtree <- bike_train %>%
  add_predictions(rtree, var = "Predicted") %>%
  dplyr::select(count, Predicted)

model_rtree_cp <- bike_train %>%
  add_predictions(rtree_overfit1, var = "Predicted") %>%
  dplyr::select(count, Predicted)

model_rctree <- bike_train %>%
  add_predictions(rctree, var = "Predicted") %>%
  dplyr::select(count, Predicted)
```

**Расчёт ошибок прогнозов, построенных на основе отобранных ранее ручных и "деревянных" моделей:**

```{r paged.print=FALSE}
errors <- function(actual, predicted) {
  error <- actual - predicted
  abs_error <- abs(actual - predicted)
  percent_error <- abs_error/actual
  
  ME <- mean(error, na.rm = T)
  MAE <- mean(abs_error, na.rm = T)
  MAPE <- mean(percent_error, na.rm = T)
  MSE <- mean(error^2, na.rm = T)
  RMSE <- sqrt(MSE)
  BIAS <- mean(sum(error)/sum(actual))
  
  tibble(ME, MAE, MAPE, MSE, RMSE, BIAS)
}

models_row <- 
  bind_rows("2" = model_2_pred, ##ручная
          "3" = model_3_pred, ##ручная
          "4" = model_4_pred, ##ручная
          "5" = model_5_pred, ##ручная
          "6" = model_6_pred, ##ручная
          "7" = model_7_pred, ##ручная
          "8" = model_8_pred, ##ручная
           "9" = model_9_pred, ##ручная
          "10" = model_rtree, ##дерево решений 
          "11" = model_rtree_cp, ##дерево решений 
          "12" = model_rctree, ##дерево решений
         
          .id = "Number")

models_row %>%
  group_by(Number) %>%
  summarise(errors = list(errors(count, Predicted))) %>%
  unnest() %>%
  arrange(MAPE) %>%
  knitr::kable()
```


**Расчёт ошибок автоматических моделей** 

```{r paged.print=FALSE}
models_row1 <- 
  bind_rows("randomForest" = performance(bike_pred_lm1,
            measures = reg_ms) ,
            "lm" = performance(bike_pred_lm,
            measures = reg_ms),
            "bcart" = performance(bike_pred_bcart1,
            measures = reg_ms),

        
         
          .id = "Number")

models_row1 %>%
  group_by(Number) %>%
  
  unnest() %>%
  arrange(mape) %>%
  knitr::kable()

```

**Вывод:** 

1) Таким образом, можно выделить "модель-победительницу" на обучающей выборке - это автоматическая модель "randomForest". Она обладает наименьшей MAPE, MSE, RMSE и MAE по сравнению с остальными отобранными моделями.

2) Второе место берёт ручная модель №9, которая представляет из себя модифицированную модель №6, проверенной на выборке без значимых выбросов и лишённой гетеродоксичносности. Она показала наименьшую ошибку MAPE c небольшим отрывом от остальных моделей и наименьшие значения остальных ошибок среди остальных оставшихся моделей.

3) Третье место забирает модель №7  - это модель №6 с переменой atemp вместо temp. Она обладает чуть большей MAPE, MAE, MSE, RMSE, чем у первых двух моделей в рейтинге, но чуть меньшими ME и BIAS, чем у модели, занявшей второе место. 

4) Остальные модели являются "аутсайдерами".

# 7) Прогнозы ручных моделей на тестовой выборке и сравнение ошибок

**Построение прогнозов выбранными моделями на тестовой выборке:**


```{r}

model_test_7 <- lm(count^0.308 ~ temp +  daytime + I(daytime^2)+ workingday + I(month^2)+ humidity + daytime*workingday + month + weather*daytime, data = bike_test)
model_test7_pred <- bike_test %>%
  add_predictions(model_test_7, var = "Predicted") %>%
  mutate(Predicted = Predicted^(1/0.308)) %>%
  dplyr::select(count, Predicted)

model_test_9 <- lm(count^0.314 ~  atemp + daytime + I(daytime^2) + humidity + daytime*workingday + month*daytime + weather*daytime +  humidity*month + humidity*daytime, data = bike_test)
model_test9_pred <- bike_test %>%
  add_predictions(model_test_9, var = "Predicted") %>%
  mutate(Predicted = Predicted^(1/0.314)) %>%
  dplyr::select(count, Predicted)



```

**Расчёт ошибок прогнозов моделей №7 и №8 на тестовой выборке:**

```{r paged.print=FALSE}
errors <- function(actual, predicted) {
  error <- actual - predicted
  abs_error <- abs(actual - predicted)
  percent_error <- abs_error/actual
  
  ME <- mean(error, na.rm = T)
  MAE <- mean(abs_error, na.rm = T)
  MAPE <- mean(percent_error, na.rm = T)
  MSE <- mean(error^2, na.rm = T)
  RMSE <- sqrt(MSE)
  BIAS <- mean(sum(error)/sum(actual))
  
  tibble(ME, MAE, MAPE, MSE, RMSE, BIAS)
}

models_row_test <- 
  bind_rows(
          "7" = model_test7_pred, 
          "8" = model_test9_pred,
         
          .id = "Number")

models_row_test %>%
  group_by(Number) %>%
  summarise(errors = list(errors(count, Predicted))) %>%
  unnest() %>%
  arrange(MAPE) %>%
  knitr::kable()
```

**Прогноз "randomForest" на тестовой выборке:** 

```{r}
bike_mod_lm11 <- train(lrn_lm1, task = bike_task, 
                    subset = bike_train_task1)

bike_pred_lm11 <- predict(bike_mod_lm11, 
                       task = bike_task, 
                       subset = bike_test_task1)

reg_ms <- list(rmse, mape, mae)

performance(bike_pred_lm11,
            measures = reg_ms) %>%
  round(2)
```


**Вывод:** наилучшей регрессионной моделью на тестовой выборке стала модель №9. Она обладает наименьшей MAPE, совсем незначительно большими значениями других ошибок по сравнению с моделью, занявшей второе место. Второе место - модель №8, а третье - автоматическая модель "randomForest".

**Таким образом, удалось определить наилучшую регрессионную модель для прогнозирования, которая показала наилучшие показатели ошибок на тестовой выборке — это модель №9, которая включала в себя множественную регрессию переменных, которая была протестирована на выборке, лишённой значимых выбросов, взаимосвязь переменных, а также избавленной от возможной гетеродокичности. Эта модель заняла третье место по точности прогнозирования на обучающей выборке, но это не помешало ей занять первое место на тестовой выборке. В заключение хотелось бы сказать, что найденная нами регрессионная модель позволяет довольно точно предсказывать значения целевой переменной - число актов аренды велосипедов в зависимости от некоторых внешних факторов, которые определены другими переменными в датасете.**
