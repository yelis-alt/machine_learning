---
title: "Asphalt"
output: html_document
---

# Настройка вывода данных:

```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(width = 100) # ширина текстового вывода
options(digits = 3) # число знаков после запятой в выводе
```

# Подключение необходимых библиотек:

```{r}
library(readr)
library(tidyverse) 
library(ggplot2) 
library(ggfortify) 
library(modelr) 
library(broom) 
library(GGally)
library(forcats) 
library(tidyr)
library(car)
library(dplyr)
library(glmnet)
library(memisc) 
library (gridExtra)
```

# Описание переменных

- `Cement`: цемент (кг/м3)	
- `Slag`: доменный шлак	(кг/м3)  
- `Fly ash`: зола (кг/м3)	  
- `Water`: вода (кг/м3)	  
- `SP`: суперпластификатор (кг/м3)  
- `Coarse Aggr.`: грубый заполнитель (кг/м3)	
- `Fine Aggr.`: мелкий заполнитель (кг/м3)	
- `SLUMP`: "осадка"" бетона (см) (https://www.youtube.com/watch?v=lwZf217v5XA)  
- `FLOW`: текущесть бетона (cм)	(https://www.youtube.com/watch?v=RO5GHlTvGnA)  
- `28-day Compressive Strength`:  прочность на сжатие, целевая переменная (МПа)  
(https://www.youtube.com/watch?v=e8bH26-3PCw)


# Загрузка исходных данных:

```{r}
library(readr)
concrete_all <- read_csv("*/Concrete.csv")
View(concrete_all)
```

**Вывод:** данная выборка содержит в себе 103 наблюдения. Пропущенные значения отсутствуют. В качестве обучающей выборки будет взято 82 первых наблюдений (80%).Целевой переменной является столбец "28-day Compressive Strength", которая содержит в себе количественную оценку прочности цемента в МПа. Остальные 9 переменных также описывают количественные характеристики.

# 1) Разделение выборки на обучающую и тестовую:

```{r}
sample <- floor(0.8*nrow(concrete_all))

set.seed(102)

sample_ind <- sample(seq_len(nrow(concrete_all)),size = sample)

concrete_edu <- concrete_all[sample_ind,]
concrete_test <- concrete_all[-sample_ind,]
```

**Вывод:** удалось получить обучающую и тестовую выборку случайным образом. Все дальнейшие операции, кроме финальной проверки прогноза по выбранной модели, будут проведены с обучающей выборкой.

# 2) Разведочный анализ:

```{r}
summary (concrete_edu)
```

**Вывод:** в результате разведочного анализа не было обнаружено каких-либо явных аномальных значений, поэтому можно продвигаться дальше. Для выявления выбросов требуется отдельный анализ, который будет проведён в 4-ом пункте.

## Диаграммы рассеяния и коэффициенты корреляции:

```{r echo=FALSE, message=FALSE}
ggpairs(concrete_edu, 
        lower = list(continuous = wrap("smooth_lm", color = 'blue')))
```

**Вывод:** На диаграммах рассеяния видна зависимость между всеми параметрами. Коэффициенты корреляции ненулевые и статистически значимы.
Наибольшее влияние на целевую переменную оказывают плотность цемента, доменный шлак и зала. Взаимосвязь между остальными переменными выборки также интересна, но в виду громоздкости визуализации и большого количества переменных их описание проблематично. 

Так как в данной выборке отсутствуют качественные переменные, то можно сразу приступить к построению моделей множественной регрессии.

# 3) Модели множественной регрессии:

## Изменение имён переменных на более удобные названия:

```{r}
names(concrete_edu)[6] <- "Coarse_Aggr"
names(concrete_edu)[7] <- "Fine_Aggr"
names(concrete_edu)[8] <- "Slump"
names(concrete_edu)[9] <- "Flow"
names(concrete_edu)[3] <- "Fly_Ash"
names(concrete_edu)[2] <- "Slag"
names(concrete_edu)[10] <- "Strength"
names(concrete_test)[6] <- "Coarse_Aggr"
names(concrete_test)[7] <- "Fine_Aggr"
names(concrete_test)[8] <- "Slump"
names(concrete_test)[9] <- "Flow"
names(concrete_test)[10] <-"Strength"
names(concrete_test)[3] <- "Fly_Ash"
names(concrete_test)[2] <- "Slag"
```

## Модель №1: 'Strength' ~ 'Fly_Ash'

```{r}
Str_Fly <- lm(Strength ~ Fly_Ash, data = concrete_edu)
summary(Str_Fly)
```

**Вывод:** содержание золы и прочность цемента показывали наибольшую корреляцию, поэтому было решено построить модель с такими зависимостями первой. Данная модель регрессии статистически значимая, так как p-value = 3.97e-05 (<0.05). 

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance(Str_Fly) 
```

**Вывод:** модель смогла объяснить только 19.1% наблюдений, и её стандартная ошибка равна 7,03, что говорит о том, модель плохо справляется своими задачами и нуждается в замене альтернативами. 

## Модель №2: 'Strength' ~ 'Cement' + 'Slag' + 'Fly ash'

```{r}
Str_Cem_Sl_Fl <- lm(Strength ~ Cement + Slag + Fly_Ash, data = concrete_edu)
summary(Str_Cem_Sl_Fl)
```

**Вывод:** все коэффициенты модели значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance (Str_Cem_Sl_Fl)
```

**Вывод:** модель достаточно хорошо справилась со своей задачей - она объяснила 78.3% всех наблюдений, и её стандартная ошибка = 3.69. 

**Построение графиков остаточной диагностики:**

```{r}
autoplot (Str_Cem_Sl_Fl)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки хорошо прилегают к прямой, а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график имеет небольшую впадину в своём начале, что говорит о том, что предположение о гомоскедастичности может быть нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Модель 2.1: устранение гетероскедастичности модели №2

```{r}
ext <- car::powerTransform(Strength ~  Cement + Slag + Fly_Ash, data = concrete_edu)
coef(ext)
```

**Вывод:** возведём целевую переменную в степень 0,404, чтобы избавиться о гетероскедастичности. 

**Построение модели:**
```{r}
Str_Cem_Sl_Fl_1 <- lm(Strength^0.404 ~ Cement + Slag + Fly_Ash, data = concrete_edu)
summary(Str_Cem_Sl_Fl_1)
```

**Вывод:** все коэффициенты модели значимые, и сама она статистически значимая p-value < 2e-16 (<0.05).

```{r}
autoplot (Str_Cem_Sl_Fl_1)
```

**Вывод:** распределение остатков стало нормальнее, тем не менее осталась небольшая впадина, а остальные графики изменились в худшую сторону, хоть и в малой степени. Сложно сказать, лучше ли эта модель, поэтому следует отобрать её и сравнить с другими. 

## Модель 3: "Полная"

В этой модели будет изучено влияние одновременно всех переменных выборки на целевую.

```{r}
model_full <- lm(`Strength` ~ ., data = dplyr::select(concrete_edu, `Cement`:`Strength`))
summary (model_full)
```

**Вывод:** было решено сделать общую модель со всеми переменными. Полная модель оказалась значима (p-value: <2e-16), несмотря на то что некоторые её коэффициенты не значимы, что говорит о целесообразности её дальнейшего тестирования.

**Проверка парметров модели:**

```{r paged.print=FALSE}
glance (model_full)
```

**Вывод:** полная модель показала превосходные результаты - она объяснила 90% всех наблюдений, а её стандартная ошибка = 2.6. Эта модель хороша, но тем не менее необходимо рассмотреть и другие комбинации с целью отбора других хороших моделей для дальнейшего анализа.

**Построение графиков остаточной диагностики:**

```{r}
autoplot (model_full)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки хорошо прилегают к прямой, а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Перебор с помощью "пустой" модели

Ручной перебор всех 9 переменных с целевой занял бы крайне много времени, поэтому можно оставить эту задачу компьютеру, а потом посмотреть, какие же сочетания давали наилучшие результаты. Воспользуемся информационным критерием Акаике, который покажет нам, какие лучшие модели ему удалось выявить.

```{r}
model_empty <- lm(`Strength` ~ 1, data = dplyr::select(concrete_edu, `Cement`:`Strength`))

m_forward <- stepAIC(model_empty, 
                     scope = list(lower = model_empty, upper = model_full),
                     direction = 'forward')
```

**Вывод:** наименьшим AIC (Информационный критерий Акаике для статистики качества приближения) обладает подобранная модель С переменными: зола, плотность, вода, грубый заполнитель, осадка, текучесть и суперпластификатор. Стоит проанализировать эту модель для проверки качества её работы.

## Модель №4: 'Strength' ~ 'Fly_Ash' + 'Cement' + 'Water' + 'Coarse_Aggr' + 'Slump' + 'Flow'+ 'SP'

```{r}
AIC_min <- lm(Strength ~ Fly_Ash + Cement + Water + Coarse_Aggr + Slump + Flow + SP, data = concrete_edu)
summary(AIC_min)
```

**Вывод:** Данная модель регрессии статистически значимая, так как p-value = 2e-16 (<0.05), несмотря на то, что один из её коэффициентов незначимый. 

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance (AIC_min)
```

**Вывод:** данная модель показала превосходные результаты - она объяснила 89.6% всех наблюдений, и её стандартное отклонение равно 2,61, что является хорошим результатом. 

**Построение графиков остаточной диагностики:**

```{r}
autoplot (AIC_min)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки хорошо прилегают к прямой, а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график имеет небольшую впадину в самом начале, что значит, что предположение о гомоскедастичности может быть нарушено. Тем не менее, как показал схожий прошлый опыт: попытка избавления от неё в данном случае может ухудшить работу модели.

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Модель №5: 'Strength' ~ 'Fly_Ash' + 'Cement' + 'Water' + 'Coarse_Aggr' + 'Slump' + 'Flow'

В этой модели попробуем избавиться незначимого коэффициента прошлой модели и проверить её работу.

```{r}
AIC_min_alt <- lm(Strength ~ Fly_Ash + Cement + Water + Coarse_Aggr + Slump + Flow, data = concrete_edu)
summary(AIC_min_alt)
```

**Вывод:** данная модель регрессии статистически значимая, так как p-value = 2e-16 (<0.05), и все её коэффициенты значимы.

**Проверка параметров модели:**

```{r paged.print=FALSE}
glance (AIC_min_alt)
```

**Вывод:** Модель показала превосходные результаты - она объяснила 89.1% наблюдений, а также её стандартное отклонение равно 2.66. Она показала чуть худшие результаты, чем предыдущая модель с одним незначимым коэффициентом, но тем не менее это довольно качественная модель.

**Построение графиков остаточной диагностики:**

```{r}
autoplot (AIC_min_alt)
```

**Вывод:** 

1) Рассеяние точек говорит о наличии нелинейной связи между переменными (линейная связь накладывается на пунктирную прямую в нуле), но тем не менее, коэффициенты нелинейной модели, основываясь на графике, не критически велики)

2) Это квантильный график для остатков. При справедливости допущения остатки на графике должны быть близкими к наклонной прямой линии. В данном случае, остатки хорошо прилегают к прямой, а некоторые наблюдения достаточно несильно отклоняются от нее. Это говорит о корректности построенной регрессионной модели.

3) Если дисперсия остатков не постоянна, то облако точек будет искривленным или иметь воронкообразную форму. Здесь же график отдалённо напоминает прямую, что говорит о том, что значит, что предположение о гомоскедастичности в целом не нарушено. 

4) Выбросы есть, но в целом модель не объясняет их поведение и сильно подстраивается под них.

## Выбор лучшей модели

**Прогноз на обучающем периоде:**

Прогнозы на обучающей выборке на основе пяти отобранных ранее регрессионных моделей:

```{r}
model_2 <- concrete_edu %>%
  add_predictions(Str_Cem_Sl_Fl, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)

model_2.1 <-  concrete_edu %>%
  add_predictions(Str_Cem_Sl_Fl_1, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)
 
model_3 <- concrete_edu %>%
  add_predictions(model_full, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)
  
model_4 <- concrete_edu %>%
  add_predictions(AIC_min, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)
   
model_5 <- concrete_edu %>%
  add_predictions(AIC_min_alt, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)
```

**Расчёт ошибок прогнозов, построенных на основе отобранных ранее моделей:**

```{r paged.print=FALSE}
errors <- function(actual, predicted) {
  error <- actual - predicted
  abs_error <- abs(actual - predicted)
  percent_error <- abs_error/actual
  
  ME <- mean(error, na.rm = T)
  MAE <- mean(abs_error, na.rm = T)
  MAPE <- mean(percent_error, na.rm = T)
  MSE <- mean(error^2, na.rm = T)
  RMSE <- sqrt(MSE)
  BIAS <- mean(sum(error)/sum(actual))
  
  tibble(ME, MAE, MAPE, MSE, RMSE, BIAS)
}

models_row <- 
  bind_rows("2" = model_2, 
          "21" = model_2.1, 
          "3" = model_3, 
          "4" = model_4, 
          "5" = model_5, 
          .id = "Number")

models_row %>%
  group_by(Number) %>%
  summarise(errors = list(errors(`Strength`, Predicted))) %>%
  unnest() %>%
  arrange(MAPE) %>%
   arrange(MSE) %>%
  knitr::kable()
```

**Вывод:** 

1) Таким образом, можно выделить "модель-победительницу" — это "полная" модель, которая включала в себе множественную регрессию всех переменных.

2) Второе место берёт модель №4 — это модель с наименьшим AIC. Она обладает одинаковой MAPE с лидером, но чуть большими MSE, RMSE и MAE.

3) Третье место забирает модель №5 — это модель с наименьшим AIC без переменной "Flow" (текучесть), которая показалась нам незначимой. Она немного уступает второму месту по таким ошибкам, как MAE, MAPE, MSE, RMSE.

4) Четвёртое место занимает Модель №2 - это модель с переменными с отдельными наибольшими коэффициентами корреляции с целевой переменной. Она немного уступает второму месту по таким ошибкам, как MAE, MAPE, MSE, RMSE.

5) Аутсайдером становится модель №2.1 — это модифицированная модель №2. При попытке избавиться от гетеродексатичности мы сделали её только хуже, поэтому она показывает наихудшие результаты.

# 4) Исследование выбросов и проверка работы выбранной модели без них:

**Построение ящика с усами для выявления выбросов:**

```{r}
box1 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Strength))
box2 <- ggplot(data = concrete_edu) +
geom_boxplot(mapping = aes(x = '', y = Cement))
box3 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Slag))
box4 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Fly_Ash))
box5 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Water))
box6 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = SP))
box7 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Coarse_Aggr))
box8 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Fine_Aggr))
box9 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Slump))
box10 <- ggplot(data = concrete_edu) +
  geom_boxplot(mapping = aes(x = '', y = Flow))

grid.arrange(box1, box2, box3, box4, box5, box6, box7, box8, box9, box10, ncol=5)
```

**Вывод:** в результате построения множественных "ящиков с усами" для каждой переменной удалось установить, что выбросы (точки за пределами коробки) в данных содержатся в трёх столбцах: Strength и SP (прочность и суперпластификатор). Возможно, наличие выбросов объясняется либо ошибками измерения параметров цемента, либо ошибкой при их фиксировании, либо барком самого исследуемого цемента. Тем не менее, они мешают найденной нами модели показывать более хорошие результаты.

**Создание выборки,свободной от выбросов:**

Согласно результатам ящичных диаграмм, установим такие ограничения на столбцы, в которых были найдены выбросы, чтобы они не вошли в их пределы  и строки, содержащие их, не вошли в новый "чистый" дата-сет.

```{r}
concrete_clean <-
                 concrete_edu %>% filter (Strength <= 55 & SP<=17)
view (concrete_clean)
```

**Вывод:** в итоге, в новый дата-сет не вошло 3 наблюдения, которые и содержали "выбросные" параметры.

**Построение полной регрессионной модели на выборке, свободной от выбросов:**

```{r}
model_full_clean <- lm(`Strength` ~ ., data = dplyr::select(concrete_clean, `Cement`:`Strength`))
summary(model_full_clean)
```

**Вывод:** Полная модель на выборке без выбросов оказалась значима (p-value: <2e-16).

**Проверка параметров полной модели на выборке без выбросов:**

```{r paged.print=FALSE}
glance (model_full_clean)
```

**Вывод:** Полная модель на выборке без выбросов смогла объяснить 89,8% наблюдений, что всего на 0,2% меньше, чем полная модель на выборке с выбросами, зато её стандартная ошибка заметно снизилась с 2.6 до 2.53 (0,07), что говорит о том, что, скорее всего, она лучше справилась со своей задачей при её применении на обучающей выборке без выбросных наблюдений.

**Построение прогноза полной моделью и расчёт её ошибок на выборке без выбросов:**

```{r paged.print=FALSE}
model_clean_pred <- concrete_clean %>%
  add_predictions(model_full_clean, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)

models_clean <- 
  bind_rows("Clean" = model_clean_pred)

models_clean %>%
  summarise(errors = list(errors(`Strength`, Predicted))) %>%
  unnest() %>%
  knitr::kable()
```

**Вывод:** таким образом, на обучающей выборке, на которой были удалены наблюдения с выбросами, у полной модели MAE снизилась с 1.94 до 1.91, MAPE осталась прежней, MSE - c 5.95 до 5.6 и RMSE - c 2.44 до 2.37. Это говорит о том, что при удалении наблюдений с выбросами прогноз, основанный на одной и той же регрессионной модели, оказался немного точнее.

# 5) Прогноз на тестовой выборке и сравнение ошибок:

**Построение прогноза полной моделью на тестовой выборке:**

```{r}
model_test <- lm(`Strength` ~ ., data = dplyr::select(concrete_test, `Cement`:`Strength`))
model_test_pred <- concrete_test %>%
  add_predictions(model_test, var = "Predicted") %>%
  dplyr::select(`Strength`, Predicted)
```

**Расчёт ошибок прогноза полной модели на тестовой выборке:**

```{r paged.print=FALSE}
models_test <- 
  bind_rows("Test" = model_test_pred)

models_test %>%
  summarise(errors = list(errors(`Strength`, Predicted))) %>%
  unnest() %>%
  knitr::kable()
```

**Вывод:** прогноз на тестовой выборке показал отличные результаты, которые могут быть выражены крайне маленькими значениями ошибок. Относительно работы на обучающей выборке, на тестовой - BIAS также осталась практически нулевой, а вот MAPE снизилась до 0,031, как и значительно снизились показатели остальных ошибок. Это свидетельствует о том, что выбранная нами регрессионная модель, включающая в себя множественную регрессию всех переменных по отношению к целевой, оказалась крайне качественной, так как и на обучающем, и на тестовом периодах мы можем увидеть крайне маленькие значения ошибок. 

**Таким образом, можно заявить, что мы нашли лучшую модель для прогнозирования регрессии, и ей является модель №3, которая учитывает влияния всех существующих переменных на целевую. Эта модель показала наименьшие ошибки при прогнозах на обучающей выборке, а также крайне низкие показатели ошибок на тестовой выборке**
